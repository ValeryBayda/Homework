{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"../input/test/images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model, load_model\n",
    "from keras_preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from segmentation_models import *\n",
    "from segmentation_models.backbones import get_preprocessing\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "\n",
    "from tensorflow.python.keras.applications import vgg16\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 101\n",
    "img_size_resize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_df = pd.read_csv('../input/depths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаю изображения и маски в датафрейм и нормализую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчет солевого покрытия и классов солевого покрытия Подсчет количества соляных пикселей в масках и деление их на размер изображения. Также создайте 11 классов покрытия, от -0.1 без соли до 1.0 только от соли. Построение графика распределения покрытий и классов покрытия, а также класса по необработанному покрытию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем классы по площади соляного покрытия на картинке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_to_class(value):    \n",
    "    for i in range(0, 11):\n",
    "        if value * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df['coverage'].map(coverage_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# взглянем на гистограммы(площадь покрытия и классы покрытия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на распределение глубины в тестовых и обучающих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на некотрые изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_images = 30\n",
    "grid_width = 15\n",
    "grid_height = int(max_images / grid_width)\n",
    "fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n",
    "for i, idx in enumerate(train_df.index[:max_images]):\n",
    "    img = train_df.loc[idx].images\n",
    "    mask = train_df.loc[idx].masks\n",
    "    ax = axs[int(i / grid_width), i % grid_width]\n",
    "    ax.imshow(img, cmap=\"Greys\")\n",
    "    ax.imshow(mask, alpha=0.4, cmap=\"Blues\")\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "plt.suptitle(\"Blue: salt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделяю данные на обучающую и валидационную выборку с учетом созданного признака:покрытие солью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_height, im_width, im_chan = 128, 128, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '../input/train/'\n",
    "path_test = '../input/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
    "test_ids = next(os.walk(path_test+\"images\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_ = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = path_train\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    X_[n] = x\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    Y_[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_,Y_, random_state=20, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построим простую модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = random.randint(0, len(X_train))\n",
    "has_mask = Y_train[ix].max() > 0 \n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 15))\n",
    "\n",
    "ax1.imshow(X_train[ix, ..., 0], cmap = 'Greys', interpolation = 'bilinear')\n",
    "if has_mask: \n",
    "    ax1.contour(Y_train[ix].squeeze(), colors = 'k', linewidths = 5, levels = [0.5])\n",
    "ax1.set_title('Seismic')\n",
    "\n",
    "ax2.imshow(Y_train[ix].squeeze(), cmap = 'gray', interpolation = 'bilinear')\n",
    "ax2.set_title('Salt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(128, 128, 1))\n",
    "\n",
    "conv_1_1 = Conv2D(32, (3, 3), padding='same')(inp)\n",
    "conv_1_1 = Activation('relu')(conv_1_1)\n",
    "\n",
    "conv_1_2 = Conv2D(32, (3, 3), padding='same')(conv_1_1)\n",
    "conv_1_2 = Activation('relu')(conv_1_2)\n",
    "\n",
    "pool_1 = MaxPooling2D(2)(conv_1_2)\n",
    "\n",
    "\n",
    "conv_2_1 = Conv2D(64, (3, 3), padding='same')(pool_1)\n",
    "conv_2_1 = Activation('relu')(conv_2_1)\n",
    "\n",
    "conv_2_2 = Conv2D(64, (3, 3), padding='same')(conv_2_1)\n",
    "conv_2_2 = Activation('relu')(conv_2_2)\n",
    "\n",
    "pool_2 = MaxPooling2D(2)(conv_2_2)\n",
    "\n",
    "\n",
    "conv_3_1 = Conv2D(128, (3, 3), padding='same')(pool_2)\n",
    "conv_3_1 = Activation('relu')(conv_3_1)\n",
    "\n",
    "conv_3_2 = Conv2D(128, (3, 3), padding='same')(conv_3_1)\n",
    "conv_3_2 = Activation('relu')(conv_3_2)\n",
    "\n",
    "pool_3 = MaxPooling2D(2)(conv_3_2)\n",
    "\n",
    "\n",
    "conv_4_1 = Conv2D(256, (3, 3), padding='same')(pool_3)\n",
    "conv_4_1 = Activation('relu')(conv_4_1)\n",
    "\n",
    "conv_4_2 = Conv2D(256, (3, 3), padding='same')(conv_4_1)\n",
    "conv_4_2 = Activation('relu')(conv_4_2)\n",
    "\n",
    "pool_4 = MaxPooling2D(2)(conv_4_2)\n",
    "\n",
    "up_1 = UpSampling2D(2, interpolation='bilinear')(pool_4)\n",
    "conc_1 = Concatenate()([conv_4_2, up_1])\n",
    "\n",
    "conv_up_1_1 = Conv2D(256, (3, 3), padding='same')(conc_1)\n",
    "conv_up_1_1 = Activation('relu')(conv_up_1_1)\n",
    "\n",
    "conv_up_1_2 = Conv2D(256, (3, 3), padding='same')(conv_up_1_1)\n",
    "conv_up_1_2 = Activation('relu')(conv_up_1_2)\n",
    "\n",
    "\n",
    "up_2 = UpSampling2D(2, interpolation='bilinear')(conv_up_1_2)\n",
    "conc_2 = Concatenate()([conv_3_2, up_2])\n",
    "\n",
    "conv_up_2_1 = Conv2D(128, (3, 3), padding='same')(conc_2)\n",
    "conv_up_2_1 = Activation('relu')(conv_up_2_1)\n",
    "\n",
    "conv_up_2_2 = Conv2D(128, (3, 3), padding='same')(conv_up_2_1)\n",
    "conv_up_2_2 = Activation('relu')(conv_up_2_2)\n",
    "\n",
    "\n",
    "up_3 = UpSampling2D(2, interpolation='bilinear')(conv_up_2_2)\n",
    "conc_3 = Concatenate()([conv_2_2, up_3])\n",
    "\n",
    "conv_up_3_1 = Conv2D(64, (3, 3), padding='same')(conc_3)\n",
    "conv_up_3_1 = Activation('relu')(conv_up_3_1)\n",
    "\n",
    "conv_up_3_2 = Conv2D(64, (3, 3), padding='same')(conv_up_3_1)\n",
    "conv_up_3_2 = Activation('relu')(conv_up_3_2)\n",
    "\n",
    "\n",
    "\n",
    "up_4 = UpSampling2D(2, interpolation='bilinear')(conv_up_3_2)\n",
    "conc_4 = Concatenate()([conv_1_2, up_4])\n",
    "conv_up_4_1 = Conv2D(32, (3, 3), padding='same')(conc_4)\n",
    "conv_up_4_1 = Activation('relu')(conv_up_4_1)\n",
    "\n",
    "conv_up_4_2 = Conv2D(1, (3, 3), padding='same')(conv_up_4_1)\n",
    "result = Activation('sigmoid')(conv_up_4_2)\n",
    "\n",
    "\n",
    "model = Model(inputs=inp, outputs=result)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy') \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=5, verbose=1),\n",
    "    ReduceLROnPlateau(patience=3, verbose=1),\n",
    "    ModelCheckpoint('model-unet.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "batch_size = 32\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    validation_data=[X_valid, Y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=callbacks, \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(train_ids)):\n",
    "    path = path_test\n",
    "    img = load_img(path + 'images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    X_test[n] = x\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights('model-unet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_valid,  Y_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "preds_train = model.predict(X_train,  verbose=1)\n",
    "preds_val = model.predict( X_valid,  verbose=1)\n",
    "preds_test = model.predict( X_test,  verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (101, 101), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_upsampled[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds):\n",
    "    ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='Greys')\n",
    "    if has_mask:\n",
    "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[0].set_title('Seismic')\n",
    "    ax[1].imshow(y[ix].squeeze())\n",
    "    ax[1].set_title('Salt')\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[2].set_title('Salt Pred');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X_train, Y_train, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X_valid, y_valid, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "    \n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "pred_dict = {id_[:-4]:RLenc(np.round(preds_test_upsampled[i] > 0.5)) for i,id_ in tqdm_notebook(enumerate(test_ids))}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
